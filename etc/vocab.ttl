# An ontology for a dataset of system logs and related information to support 
# failure analysis for large HPC clusters

# Ontology scope and competency questions:
#  - ontology describes log data for an HPC cluster (primarily target Cray
#    systems at DOE sites, but ideally more generally valid). The LogSet itself
#    is a dcat:DataSet, access to it is expected to be published as a 
#    dcat:Distribution and by an organization described in terms of foaf:Agent.
#    The system in question is described as an adms:Asset.
#  - the specifics added by this ontology are intended to support tools that 
#    collate and manipulate related sets of logs, for the purpose of 
#    investigating resiliency. Especially, logs and system-state data are 
#    stored as timestamped records of events or state, usually in some defined
#    format (eg record-per-line-in-order-of-increasing time), and often with 
#    some component-identifying information. Thus a tool should be able to use 
#    an RDF description of a LogSet to select the approprate class to 
#    instantiate to manipulate each file or data source in the LogSet
#  - A LogSet has associated Annotations: human- or tool-generated descriptions
#    of events with a timespan and links to possibly-relevraent log entries
#  - Therefore, competency questions are:
#     - which logs are relevant to system xyz during time period abc?
#     - which log entries are relevant to thhis annotation?
#     - what file and record format are used in a selected logfile?
#     - how should a tool access this LogSeries in this LogSet?
#    (some more general competency questions - more at the dcat:Dataset level
#    are eg "what LogSets are available for system xyz?")

# empty prefix for "this ontology" - replace the URL eventually:
#@prefix : <http://example.com/owl/hpc-logset/> .
# what if I use the github location to get a published version?
@prefix : <https://raw.githubusercontent.com/NERSC/LogSet/master/etc/vocab#> .

# the dataset definition is derived from the Data Catalog Vocabulary, a single
# dataset is a subtype of dcat:Dataset and can be managed as part of a 
# dcat:Catalog and published/accessed as a dcat:Distribution
@prefix dcat: <http://www.w3.org/ns/dcat#> .

# basic vocabularies used here:
# rdf and rdfs between them define essential types and relationships:
@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .
# owl adds a more constrained formal description logic for classes:
@prefix owl: <http://www.w3.org/2002/07/owl#> .
# dublin core terms, form base of dcat vocab:
@prefix dct: <http://purl.org/dc/terms/> .
# For provenance information: the publisher of a LogSet is a foaf:Agent (most
# likely an foaf:Organization), and the LogSet is comprised of logfiles for one
# or more systems, described in terms of organizational Assets (adms:Asset):
@prefix foaf: <http://xmlns.com/foaf/0.1/> .
@prefix adms: <http://www.w3.org/ns/adms#> .

# do I need and equivalent of this?
#<http://www.w3.org/ns/dcat>
#    a owl:Ontology, voaf:Vocabulary;
#    rdfs:label "The data catalog vocabulary"@en;
#    .

:LogSet
    a owl:Class ;
    rdfs:subClassOf dcat:Dataset ;
    rdfs:subClassOf [
        rdf:type owl:Restriction ;
        owl:onProperty dct:temporal ; 
          # eg:"start=2016-01-01T12:00:00+08:00 end=2016-01-05T14:45:00+08:00"
        owl:cardinality 1 ;
    ] ;
    rdfs:subClassOf [
        rdf:type owl:Restriction ;
        owl:onProperty :system ; 
          # eg: <http://portal.nersc.gov/project/m888/resilience/entities/#edison
    ] ;
    rdfs:comment ''' A LogSet is a DataSet for a specific system, spanning a 
                     specific timeframe (eg a Cray boot session on NERSC Cori). 
                     It is recommended but not enforced that a LogSet instance 
                     should have certain properties describing its provenance:   
                     # dct:title         a rdfs:Literal
                     # dct:description   a rdfs:Literal
                     # dct:publisher     a foaf:Organization
                     # dct:contactPoint  a vcard:Kind
                     It is also recommended/expected that the following 
                     attributes will be described:
                     :hasLogData     a :DataSource 
                     :hasAnnotations a :DataSource
                 ''' ;
    .

:system 
    a owl:ObjectProperty ;
    rdfs:domain :LogSeries ;
    rdfs:range adms:Asset ;
    .


:LogSeries
    a owl:Class;
    rdfs:comment ''' A "type" of logfile, eg a console or outage log. Can be 
                     used by tools to indicate how to handle a log. Must have
                     a property indicating the "canonical" format that tools
                     can assume on
                     hmm: if we have multiple source for same type of log (eg 
                     version in elasticsearch), then maybe we need an 
                     "equivalentTo" property to link them?
                 ''' ;
    rdfs:subClassOf [
        rdf:type owl:Restriction ;
        owl:onProperty :logFormat ;
        owl:cardinality 1 ;
    ] ;
    .

:LogFormatType
    a owl:class ;
    rdfs:comment ''' An entity representing how log data is organized, in order 
                     to help tools decide how to handle a give log.  
                     For example, most logs are timestamped-line-per-entry but
                     some are a timestamped multiline block, others have a file
                     per timestamp and contain a table, others hove no obvious 
                     structure at all. 
                     A LogFormatType is expected to correspond to a handler 
                     class for logs in that format
                 ''' ;
    .

:logFormat
    a owl:ObjectProperty, owl:FunctionalProperty ;
    rdfs:comment ''' An entity indicating how a LogSeries is formatted, from 
                     which tools can decide how to process it.
                     For example, most logs are timestamped-line-per-entry (in
                     a file or stream) but some are a timestamped multiline 
                     block, others have a file per timestamp and contain a 
                     table, others hove no obvious structure at all. 
                     problem: what if the 
                     same log might be in a native file or as records in a 
                     database? then the logFormat should provide enough 
                     information for a tool to answer questions about it?
                     or does that count as a different logseries?
                 ''' ;
    rdfs:domain :LogSeries ;
    rdfs:range :LogFormatType ;
    #rdfs:domain :DataSource ;
    .


#:RecordFormat
#    a owl:class ;
#    rdfs:comment '''Indicates how a record within this LogSeries is formatted, 
#                    therefore how to process it. Especially, how to identify
#                    the beginning and end of a record, and how to read the 
#                    timestamp associated with a record
#                 ''' ;
#    .

:logFormatInfo
    a owl:ObjectProperty ;
    rdfs:comment ''' dictionary-like information that a LogFormatType handler 
                     class can use to interpret a specific type of logfile. Each 
                     logFormatInfo property should be a literal like 
                     "key=value". Eg, a console_logfile and message_logfile are
                     both timeStampedLogFile, but in the console log the 
                     timestamp is the first "word" on each line, while in the 
                     message log the timestamp is the second word on each line.
                     So console_logfile can have recordInfoProperty "ts_word=0"
                     (and "part_word=1" for system component) 
                 ''' ;
    rdfs:domain :LogSeries ;
    rdfs:range rdfs:Literal ;
    #rdfs:domain :DataSource ;
    #rdfs:range :RecordFormat ;
    .


:DataSource
    a owl:class ;
    # required properties:
    rdfs:subClassOf [
        rdf:type owl:Restriction ;
        owl:onProperty dcat:mediaType ; # eg "application/json" or "text/plain"
        owl:cardinality 1 ;
    ] ;
    rdfs:comment ''' general accessor for log data, eg a File or database or web 
                     service. Used to identify a class to instantiate that can 
                     interpret between how the datasource holds/exposes the data 
                     and the canonical logFormat for the LogSeries 
                     (eg, one DataSource might provide access to a file holding 
                     a console log, another to a database holding it - but the 
                     accessor for each should provide data in the format 
                     described by the LogSeries)
                 ''' ;
    .

:File
    a owl:class ;
    rdfs:subClassOf :DataSource ; 
    # required properties:
    rdfs:subClassOf [
        rdf:type owl:Restriction ;
        owl:onProperty :path ; # eg "/abs/path/to/file" or "../rel/path/to/file"
        owl:cardinality 1 ;
    ] ;
    .

:path
    a owl:DatatypeProperty ;
    rdfs:comment "path relative to the index.ttl file" ;
    rdfs:domain :File ;
    rdfs:range rdfs:Literal ;
    .

:hasLogData
    a owl:ObjectProperty ;
    rdfs:comment "Links log data (eg a log file) to a LogSet" ;
    rdfs:domain :LogSet ;
    rdfs:range :DataSource ;
    .

:isLogOf
    a owl:ObjectProperty, owl:FunctionalProperty ;
    rdfs:comment "Links a LogSeries to log data (eg a log file)" ;
    rdfs:domain :DataSource ;
    rdfs:range :LogSeries ;
    .

:hasAnnotations
    a owl:ObjectProperty ;
    rdfs:comment "Links annotation data to a LogSet" ;
    rdfs:domain :LogSet ;
    rdfs:range :DataSource ;
    .

# =========


## -------
#
# some example things within a dataset:
#
# BEGIN=p0-<timestamp> file. Empty file, marks start of boot session
#
# bootinfo.p0-20170906t151820. seems to have output of commands, delimited by 
#                              start-of-line timestamps. Some output lines are 
#                              also prefixed by timestamp, but not all
# bootrecord/boothistory       timestamped log  
#           /boot_record       blocks of text, each coresponding to a log entry
#           /node_table        some sort of table
# bootrecorder-<datestamp>     timestamped log
# compute/<nodename>-<datestamp> timestamped log
# config.p0-<timestamp>        unstructured text
# console-<datestamp>          timestamped log
# console.pid.p0               unstructured text
# console.p0-20170906t151820   empty file
# console.cmd.p0               unstructured text
# consumer-<datestamp>         timestamped blocks of text               
# craylog.p0-20170906t151820   multiple sections, including tables, logs and unstructured text
# craylog.p0-<timestamp>.save* appears to be manually captured state of main craylog
#                              at a couple of points in time. Not part of each dataset
# dumpd-<datestamp>            timestamped log
# dws/dwmd-<datestamp>         timestamped log
# hwerrlog.p0-20170906t151820            binary data
# hwerrlog.p0-20170906t151820.<number>   binary data
# hwinv.p0-20170906t151820     xml 
# messages-<datestamp>         timestamped log
# nersc.aries_lcb/<cluster>_aries_lcb_status.<timestamp>.xz table
# netwatch-<datestamp>         table with timestamp columns
# nlrd-<datestamp>             timestamped log
# etc
#
# will also need to have annotations db, and event log (eg outages), and perhaps job info
# (maybe a db, or log, or both)
#
# so file types will need to reflect this.
# maybe each thing has a label, and a rule for the filename pattern


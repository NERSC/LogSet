# An ontology for a dataset of system logs and related information to support 
# failure analysis for large HPC clusters

# empty prefix for "this ontology" - replace the URL eventually:
@prefix : <http://example.com/owl/hpc-logset/> .

# the dataset definition is derived from the Data Catalog Vocabulary, a single
# dataset is a subtype of dcat:Dataset and can be managed as part of a 
# dcat:Catalog and published/accessed as a dcat:Distribution
@prefix dcat: <http://www.w3.org/ns/dcat#> .

# basic vocabularies used here:
# rdf and rdfs between them define essential types and relationships:
@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .
# owl adds a more constrained formal description logic for classes:
@prefix owl: <http://www.w3.org/2002/07/owl#> .
# dublin core terms, form base of dcat vocab:
@prefix dct: <http://purl.org/dc/terms/> .
# For provenance information: the publisher of a LogSet is a foaf:Agent (most
# likely an foaf:Organization), and the LogSet is comprised of logfiles for one
# or more systems, described in terms of organizational Assets (adms:Asset):
@prefix foaf: <http://xmlns.com/foaf/0.1/> .
@prefix adms: <http://www.w3.org/ns/adms#> .

:LogSet
    a owl:Class ;
    rdfs:subClassOf dcat:Dataset ;
    rdfs:subClassOf [
        rdf:type owl:Restriction ;
        owl:onProperty dct:temporal ; 
          # eg:"start=2016-01-01T12:00:00+08:00 end=2016-01-05T14:45:00+08:00"
        owl:cardinality 1 ;
    ] ;
    rdfs:comment ''' A LogSet is a DataSet spanning a specific timeframe (eg a 
                     Cray boot session). It is recommended but not enforced 
                     that a LogSet instance should have certain properties 
                     describing its provenance:   
                     # dct:title         a rdfs:Literal
                     # dct:description   a rdfs:Literal
                     # dct:publisher     a foaf:Organization
                     # dct:contactPoint  a vcard:Kind
                 ''' ;
    .

:LogSeries
    a owl:Class;
    rdfs:comment ''' A "type" of logfile, eg a console or outage log. Can be 
                     used by tools to indicate how to handle a log. Must have
                     a property indicating the format
                 ''' ;
    rdfs:subClassOf [
        rdf:type owl:Restriction ;
        owl:onProperty :logFormat ;
        owl:cardinality 1 ;
    ] ;
    .

:DataFormat
    a owl:class ;
    rdfs:comment ''' An entity representing how log data is organized, in order 
                     to help tools decide how to handle a give log.  
                     For example, most logs are timestamped-line-per-entry but
                     some are a timestamped multiline block, others have a file
                     per timestamp and contain a table, others hove no obvious 
                     structure at all. 
                 ''' ;
    .

:timeStampedLog   a :DataFormat .
:filePerTimepoint a :DataFormat .
:unstructured     a :DataFormat .
:sqlite3          a :DataFormat .
:binary           a :DataFormat .
 
:logFormat
    a owl:ObjectProperty, owl:FunctionalProperty ;
    rdfs:comment ''' An entity indicating how a LogSeries is formatted, from 
                     which tools can decide how to process it.
                     For example, most logs are timestamped-line-per-entry but
                     some are a timestamped multiline block, others have a file
                     per timestamp and contain a table, others hove no obvious 
                     structure at all. 
                 ''' ;
    rdfs:domain :LogSeries ;
    rdfs:range :DataFormat ;
    owl:oneOf(:timeStampedLog :filePerTimepoint :unstructured :sqlite3 :binary) ;
    .

:RecordFormat
    a owl:class ;
    rdfs:comment '''Indicates how a record within this LogSeries is formatted, 
                    therefore how to process it. Especially, how to identify
                    the beginning and end of a record, and how to read the 
                    timestamp associated with a record
                 ''' ;
    .

:recordFormat
    a owl:ObjectProperty, owl:FunctionalProperty ;
    rdfs:comment '''Indicates how a record within this LogSeries is formatted, 
                    therefore how to process it. Especially, how to identify
                    the beginning and end of a record, and how to read the 
                    timestamp associated with a record
                 ''' ;
    rdfs:domain :LogSeries ;
    rdfs:range :RecordFormat ;
    .


:DataSource
    a owl:class ;
    # required properties:
    rdfs:subClassOf [
        rdf:type owl:Restriction ;
        owl:onProperty dcat:mediaType ; # eg "application/json" or "text/plain"
        owl:cardinality 1 ;
    ] ;
    rdfs:comment ''' general accessor for log data, eg a File or database or web 
                     service
                 ''' ;
    .

:File
    a owl:class ;
    rdfs:subClassOf :DataSource ; 
    # required properties:
    rdfs:subClassOf [
        rdf:type owl:Restriction ;
        owl:onProperty :path ; # eg "/abs/path/to/file" or "../rel/path/to/file"
        owl:cardinality 1 ;
    ] ;
    .

:path
    a owl:DatatypeProperty ;
    rdfs:domain :File ;
    rdfs:range rdfs:Literal ;
    .

:hasLogData
    a owl:ObjectProperty ;
    rdfs:comment "Links log data (eg a log file) to a LogSet" ;
    rdfs:domain :LogSet ;
    rdfs:range :DataSource ;
    .

:isLogOf
    a owl:ObjectProperty, owl:FunctionalProperty ;
    rdfs:comment "Links log data (eg a log file) to a LogSeries" ;
    rdfs:domain :DataSource ;
    rdfs:range :LogSeries ;
    .

:hasAnnotations
    a owl:ObjectProperty ;
    rdfs:comment "Links annotation data to a LogSet" ;
    rdfs:domain :LogSet ;
    rdfs:range :DataSource ;
    .

:filePattern
    a owl:DatatypeProperty ;
    rdfs:comment ''' Python-style regex for filepaths, optionally including 
                     the following named groups (the actual format is defined
                     by the regex itself):
                       <date>  datestamp 
                       <time>  timestamp 
                       <comp>  component identifier
                     Eg: "console-(?P<date>20\\d\\d[01]\\d[0-3]\\d)"
                     (note in this eg the backslashes are doubled to make the
                     string a legal RDF literal)
                 ''' ;
    rdfs:range rdfs:Literal ;
    .



# =========


## -------
#
# some example things within a dataset:
#
# BEGIN=p0-<timestamp> file. Empty file, marks start of boot session
#
# bootinfo.p0-20170906t151820. seems to have output of commands, delimited by 
#                              start-of-line timestamps. Some output lines are 
#                              also prefixed by timestamp, but not all
# bootrecord/boothistory       timestamped log  
#           /boot_record       blocks of text, each coresponding to a log entry
#           /node_table        some sort of table
# bootrecorder-<datestamp>     timestamped log
# compute/<nodename>-<datestamp> timestamped log
# config.p0-<timestamp>        unstructured text
# console-<datestamp>          timestamped log
# console.pid.p0               unstructured text
# console.p0-20170906t151820   empty file
# console.cmd.p0               unstructured text
# consumer-<datestamp>         timestamped blocks of text               
# craylog.p0-20170906t151820   multiple sections, including tables, logs and unstructured text
# craylog.p0-<timestamp>.save* appears to be manually captured state of main craylog
#                              at a couple of points in time. Not part of each dataset
# dumpd-<datestamp>            timestamped log
# dws/dwmd-<datestamp>         timestamped log
# hwerrlog.p0-20170906t151820            binary data
# hwerrlog.p0-20170906t151820.<number>   binary data
# hwinv.p0-20170906t151820     xml 
# messages-<datestamp>         timestamped log
# nersc.aries_lcb/<cluster>_aries_lcb_status.<timestamp>.xz table
# netwatch-<datestamp>         table with timestamp columns
# nlrd-<datestamp>             timestamped log
# etc
#
# will also need to have annotations db, and event log (eg outages), and perhaps job info
# (maybe a db, or log, or both)
#
# so file types will need to reflect this.
# maybe each thing has a label, and a rule for the filename pattern

